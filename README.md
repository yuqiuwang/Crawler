# Crawler
## 分享一些爬虫脚本

----------------------------------------------------------
### 20180724

添加了脚本 selenium_lianjia.py

该脚本使用了selenium框架，爬取链接网成都高新区二手房价


----------------------------------------------------------
### 20180726

添加脚本 requests_gitbook.py

该脚本使用requests及lxml模块进行数据爬取

使用了threading模块，进行多线程操作

爬取gitbook上书籍信息，及对应的url链接

----------------------------------------------------------
### 20180727

添加脚本 proxies.py

该脚本提取 http://www.xicidaili.com/nn 网站IP信息

并测试IP地址的可用性

使用方法：

	###################################################### 
    #   import proxies
    #   IPs = proxies.ProxiesGet(1, "http://www.baidu.com")()
	#
    #	1 替换http://www.xicidaili.com上需要提取的页数，一般1页就够用了
	#	"http://www.baidu.com" 替换为用于测试IP地址的网页
    #	
    #
    # 	返回IP地址list
    #   ["http://101.236.18.101:8866","http://101.236.60.48:8866"...]
	######################################################

----------------------------------------------------------
###